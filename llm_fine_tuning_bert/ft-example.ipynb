{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be94e6d6-4096-4d1a-aa58-5afd89f33bff",
   "metadata": {},
   "source": [
    "# Fine-tuning Sandbox\n",
    "\n",
    "Code authored by: Shawhin Talebi <br>\n",
    "Blog link: https://medium.com/towards-data-science/fine-tuning-large-language-models-llms-23473d763b91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9edab25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0+cu118\n",
      "CUDA disponible: True\n",
      "Nombre de la GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print(\"CUDA disponible:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Nombre de la GPU:\", torch.cuda.get_device_name(0))\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ef8ea85-d04d-4217-99a3-21c446bf2ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhoyoso\\.conda\\envs\\pytorch-gpu-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig, \n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer)\n",
    "\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6a4484-07d8-49dd-81ef-672105f53ebe",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa9722d3-0609-4aea-9585-9aa2cfc1fc9a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # how dataset was generated\n",
    "\n",
    "# # load imdb data\n",
    "# imdb_dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# # define subsample size\n",
    "# N = 1000 \n",
    "# # generate indexes for random subsample\n",
    "# rand_idx = np.random.randint(24999, size=N) \n",
    "\n",
    "# # extract train and test data\n",
    "# x_train = imdb_dataset['train'][rand_idx]['text']\n",
    "# y_train = imdb_dataset['train'][rand_idx]['label']\n",
    "\n",
    "# x_test = imdb_dataset['test'][rand_idx]['text']\n",
    "# y_test = imdb_dataset['test'][rand_idx]['label']\n",
    "\n",
    "# # create new dataset\n",
    "# dataset = DatasetDict({'train':Dataset.from_dict({'label':y_train,'text':x_train}),\n",
    "#                              'validation':Dataset.from_dict({'label':y_test,'text':x_test})})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de226234-c521-4577-802c-0e7079ef4364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = load_dataset('shawhin/imdb-truncated')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eb8e4f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.lib.ChunkedArray object at 0x0000026AFC4D1850>\n",
       "[\n",
       "  [\n",
       "    \". . . or type on a computer keyboard, they'd probably give this eponymous film a rating of \"10.\" After all, no elephants are shown being killed during the movie; it is not even implied that any are hurt. To the contrary, the master of ELEPHANT WALK, John Wiley (Peter Finch), complains that he cannot shoot any of the pachyderms--no matter how menacing--without a permit from the government (and his tone suggests such permits are not within the realm of probability). Furthermore, the elements conspire--in the form of an unusual drought and a human cholera epidemic--to leave the Wiley plantation house vulnerable to total destruction by the Elephant People (as the natives dub them) to close the story. If you happen to see the current release EARTH, you'll detect the Elephant People are faring less well today.\",\n",
       "    \"During 1933 this film had many cuts taken from it because it was very over the top for the story content and the fact that Lily Powers,(Barbara Stanwyck) would do anything to obtain great wealth and power. Lily's father had forced his daughter into prostitution at the age of 14 and she grew up in a steel mill of a town with very poor people and her father ran a speakeasy which brought into his home all kinds of male characters who had their eye on Lily. As the story progresses, Lily meets up with man after man and eventually finds a guy who has everything and is a playboy bank president It is great to see a very young John Wayne, (Jimmy McCoy Jr.) who was only 25 when this picture was produced and Jimmy did not even get to first base with Lily, not even for lunch. A very young George Brent, (Coutland Trenholm) stars along with Barbara Stanwyck and both gave outstanding performances. This is a great film from 1933 which was produced by Darryl F. Zanuck and was locked up in a fault for many years and just recently is being shown on the silver screen. This film is rather mild compared to what we view on the Hollywood screens today, but in 1933 it was very naughty to watch this type of film. Enjoy\",\n",
       "    \"Let me be clear. I've used IMDb for years. But only today I went through the trouble of registering on the site, just so I could give this movie the lowest possible rating. I've seen hundreds of films, some of them bad, a few awful. Never, though, have i seen such a contrast of pretense and incompetence, of high intentions and failure.<br /><br />Mira Sorvino is horribly cast as the princess, but entirely unbelievable as Phocion, a young boy. Fiona Shaw is always an entertaining character, but the dialogue in the film is much worse, even, than in the insipid French play that is the source (Marivaux never reached Hollywood until now, and we should keep it that way).<br /><br />To illustrate, for example, that Leontine is a brilliant, passionate philosopher and scientist, she is shown frantically pouring chemicals from beaker to beaker, shouting out names of famous scientists. And the romance between Agis and the princess is played even sillier. For this, the pair should receive a joint 'Clair Danes' award, which in a just world would be awarded for gratuitously anachronistic and uninspired re-interpretation of interesting teens from literature as brats of the 1990's (see Miss Danes in Les Miserables).<br /><br />Aside from the atrocious plot and dialogue, there are some attempts to introduce artistic tropes into the filming. For example, there are moments when a handful of spectators are faded in and out of view of the action, sitting in chairs, watching the principal characters. The Director wants us to realize she's adapted a play. I get it. But it doesn't happen at all until far into the film. At that point, seeing a crowd of people sitting in chairs for a moment, then disappearing, is creepy and distracting. They're like some sort of un-scary zombie crowd, appearing through the mists, filling us with dread. When you see the horrible frolic and song that ends this movie, you'll want to rouse your own crowd of zombies and kill them all for the grave injustise of poisoning your mind for 112 minutes.<br /><br />-Matthew McGuire\",\n",
       "    \"Carlos Mencia was excellent this is hour special. He was working hard to show everybody he was the real deal. I know people have said he's stolen material in this special, but that is not true. Carlos brings comedy up front the way he wants it, not how anyone else wants it, that is why he is so good. People say he's not funny because he says Dee dee dee too much, and they still haven't realized thats part of his act, and they don't want it that way, but he brings it like that anyway, and succeeds in making people laugh. For all the haters out there, here is a message, Carlos is here to stay, you have no point in trying to bring him down.\",\n",
       "    \"I was initially dubious about this movie (merely because of the subject), but the richly drawn characters, the fabulous scenes of the buffalo hunt, and the dramatic conclusion make it well-worth watching. I initially had trouble distinguishing between the two buffalo hunters but as the movie progressed they increasingly distinguished themselves. I am still haunted by the final scene.\",\n",
       "    ...\n",
       "    \"I've seen this movie today for the first time and I never heard of it before, probably because of it's poor message. <br /><br />First of all, the directing itself is quite good, the actors played well and the CGI (I'm not a fan of CGI) is magnificent. But that alone doesn't make a movie. No story at all, no message behind beautiful exploited talents.<br /><br />Or do I have to make people remember, the art of a director is not only your vision but to know how to tell a story. And this is what's missing the whole 7 minutes.<br /><br />There for a simple 4 rating.\",\n",
       "    \"The Incredible Melting Man plays like an extended episode of The Six Million Dollar Man, but with violence and some nudity. I know this film is a bit crummy but I found it impossible not to kind of like it.<br /><br />The acting and script are not the best. But the effects are good for a 30 year old movie with a budget of $50 - the title character takes quite a while to actually melt but when he does it's reasonably impressive; we also have one inventive death scene involving electrocution. Of note too is the music, it's insane - a cheese-tastic medley of nonsense.<br /><br />Notable highlights: <br /><br />* Marvel at the slow-motion nurse who jumps through a pane of glass for absolutely no reason whatsoever.<br /><br />* Be amazed by a day in the life of a severed head.<br /><br />* Beware of the psychotic cannibalistic melting humanoid. Called Steve.<br /><br />* Be astonished when our hero takes a break from hunting the melting lunatic to have a bowl of soup and complain about insufficient crackers in the kitchen.<br /><br />This film is just too 70's for me to hate it. It's tacky and trashy but I thought it was a lot of fun. You could do a lot worse.\",\n",
       "    \"With Adam Sandler.<br /><br />This is without a doubt one of the most idiotic films ever made. It's about cruise ship waiter Shecky (Sandler) wanting to be a comedian on the cruise ship. First off, there is not one funny or clever line in the entire movie honestly. It is so unfunny it's pathetic. There is surprisingly not much crude or sexual humor, but the f-word is plentiful. The budget is really low, and that also ruins the film. It takes place on a cruise ship, but it seems they only had money to rent out a small boat and only had money for 10 ship extras, one of which is Billy Bob Thornton. The opening credits are animated reeeeeaally cheaply, and it is just pathetic. I hate this movie and everyone else that sees this will hate it too.<br /><br />86 mins. rated R for Language.\",\n",
       "    \"POSSIBLE SPOILER - In some way \"How to Alienate Friends....\" is the \"loser learns to adjust, becomes successful and finds out that something else matter more\" type of story, situated in the celebrity business. - END OF SPOILER <br /><br />I don't know the original book but this comedy delivers several good moments. Though I do think the ending is flawed. It felt too fast and too abrupt, as if something was missing. Besides I'd say the movie isn't able to keep a high level. Apart from this you'll find a sweet selection of actors and actresses with sometimes controversial acting qualities. Until now I've never seen Pegg any different. Still he is a very unique type though on the screen he sometimes might seem a little more tedious than necessary. Fox proved she is capable to play a hot starlet with her head in the clouds. Don't know whether it was a hard thing to do, but her performance was hot and way better than during \"Transformers\" (okay... probably that's no tough match). Kirsten Dunst is very much Kirsten Dunst (again) and you may like it (as I do) or find it annoying. On the other hand you'll see Anderson who proved her acting skills and Jeff Bridges (who is fine but perhaps he could have acted a little more powerful). They all fit their character well enough.<br /><br />Conclusion: I think it's a nice celeb comedy with some more and some less funny passages, a sweet cast but an all too sudden ending.\",\n",
       "    \"Not the worst movie I've seen but definitely not very good either. I myself am a paintball player, used to play airball a lot and going from woods to airball is quite a large change. The movie portrays similar qualitys First of all the movie starts off with this team that apparently is trying to shoot this \"Phantom\" guy or whatever, they appear to be a professional team and wear jerseys and shoot mags, autocockers. One guy sporting a bushy. Not much wrong with the movie but more how it's perceived it was very cheesy. A bunch of kids who are the good guys are woodsball players who don't appear to have much money and have dreams of getting \"better guns\". Another team constantly picks on them and insults them because they play woods and blah blah blah The phantom helps these woodsball kids out and trains them and all this crap, he gets them to play airball and basically defeats all the teams including the \"professionals\".<br /><br />So what exactly is wrong with the movie? Well the budget is a huge thing, a paintball movie WOULDN'T be bad but the budget is pretty low and the movie feels like it was done by an amateur. There are no big names in this film and the acting is very cheesy. The perception of paintball is pretty bad too. They seem to imply that everyone is going to speedball and all this other crap. It just was a lousy movie in my opinion and doesn't give a real perception what paintball is. To be honest real paintball isn't all buddy like, it's a lot of cussing and bonus balling not \"respect\" and playing by the rules. Don't watch this movie and then expect to go to a field screaming \"4 is 1!!\"\"\n",
       "  ]\n",
       "]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data['train']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5625faa-5fea-4334-bd38-b77de983d8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display % of training data with label=1\n",
    "np.array(dataset['train']['label']).sum()/len(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3644c68d-9adf-48a4-90a2-8fd89555a302",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a60dd1fe-8144-4678-b018-20891e49237a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = 'distilbert-base-uncased'\n",
    "# model_checkpoint = 'roberta-base' # you can alternatively use roberta-base but this model is bigger thus training will take longer\n",
    "\n",
    "# define label maps\n",
    "id2label = {0: \"Negative\", 1: \"Positive\"}\n",
    "label2id = {\"Negative\":0, \"Positive\":1}\n",
    "\n",
    "# generate classification model from model_checkpoint\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "853002f8-d39c-4bc4-8d07-e44a47de3b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display architecture\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc98609-873d-455c-bac4-155632cda484",
   "metadata": {},
   "source": [
    "### preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fe08707-657f-4e66-aa72-84899c54bf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n",
    "\n",
    "# add pad token if none exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20f4adb9-ce8f-4f54-9b94-300c9daae1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenize function\n",
    "def tokenize_function(examples):\n",
    "    # extract text\n",
    "    text = examples[\"text\"]\n",
    "\n",
    "    #tokenize and truncate text\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7600bcd-7e93-4fb4-bd8d-ffc76bed1ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4149.34 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4525.06 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize training and validation datasets\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f8e85f9-1804-4f49-a783-4da59580ea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd9a120-580d-470c-a981-7c7e22604865",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a894819-2e9c-4a53-9790-32130c182bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import accuracy evaluation metric\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c07b9be2-a3f6-4b38-b9e8-6a2bc8aa945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an evaluation function to pass into trainer later\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47500035-a555-46e0-83dc-440586d96b7e",
   "metadata": {},
   "source": [
    "### Apply untrained model to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f3761c1-a297-45c8-882e-d74856259810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained model predictions:\n",
      "----------------------------\n",
      "It was good. - Positive\n",
      "Not a fan, don't recommed. - Positive\n",
      "Better than the first one. - Positive\n",
      "This is not worth watching even once. - Positive\n",
      "This one is a pass. - Positive\n"
     ]
    }
   ],
   "source": [
    "# define list of examples\n",
    "text_list = [\"It was good.\", \"Not a fan, don't recommed.\", \"Better than the first one.\", \"This is not worth watching even once.\", \"This one is a pass.\"]\n",
    "\n",
    "print(\"Untrained model predictions:\")\n",
    "print(\"----------------------------\")\n",
    "for text in text_list:\n",
    "    # tokenize text\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "    # compute logits\n",
    "    logits = model(inputs).logits\n",
    "    # convert logits to label\n",
    "    predictions = torch.argmax(logits)\n",
    "\n",
    "    print(text + \" - \" + id2label[predictions.tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff356f78-c9fd-4f2b-8f5b-097cf29c1c08",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4dde538-cd7f-4ab5-a96d-c30f3003822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n",
    "                        r=4,\n",
    "                        lora_alpha=32,\n",
    "                        lora_dropout=0.01,\n",
    "                        target_modules = ['q_lin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1391303-1e16-4d5c-b2b4-799997eff9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='SEQ_CLS', inference_mode=False, r=4, target_modules={'q_lin'}, lora_alpha=32, lora_dropout=0.01, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e0d9408-9fc4-4bd3-8d35-4d8217fe01e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 628,994 || all params: 67,584,004 || trainable%: 0.9306847223789819\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5db78059-e5ae-4807-89db-b58ef6abedd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 1e-3\n",
    "batch_size = 4\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9244ed55-65a4-4c66-8388-55efd87bceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= model_checkpoint + \"-lora-text-classification\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc8bc705-5dd7-4305-a797-399b2b0fa2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2500/2500 07:41, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.324151</td>\n",
       "      <td>{'accuracy': 0.899}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.423100</td>\n",
       "      <td>0.378263</td>\n",
       "      <td>{'accuracy': 0.912}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.423100</td>\n",
       "      <td>0.551821</td>\n",
       "      <td>{'accuracy': 0.887}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.528009</td>\n",
       "      <td>{'accuracy': 0.905}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.697819</td>\n",
       "      <td>{'accuracy': 0.903}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>0.819232</td>\n",
       "      <td>{'accuracy': 0.885}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>0.837926</td>\n",
       "      <td>{'accuracy': 0.905}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.862873</td>\n",
       "      <td>{'accuracy': 0.9}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.877883</td>\n",
       "      <td>{'accuracy': 0.906}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.864343</td>\n",
       "      <td>{'accuracy': 0.902}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2500, training_loss=0.14165941982269287, metrics={'train_runtime': 462.2614, 'train_samples_per_second': 21.633, 'train_steps_per_second': 5.408, 'total_flos': 1112510053682688.0, 'train_loss': 0.14165941982269287, 'epoch': 10.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creater trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator, # this will dynamically pad examples in each batch to be equal length\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5664d1-9bd2-4ce1-bc24-cab5adf80f49",
   "metadata": {},
   "source": [
    "### Generate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5dc029e-1c16-491d-a3f1-715f9e0adf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model predictions:\n",
      "--------------------------\n",
      "It was good. - Positive\n",
      "Not a fan, don't recommed. - Negative\n",
      "Better than the first one. - Positive\n",
      "This is not worth watching even once. - Negative\n",
      "This one is a pass. - Negative\n"
     ]
    }
   ],
   "source": [
    "model.to('cuda') # moving to mps for Mac (can alternatively do 'cpu')\n",
    "\n",
    "print(\"Trained model predictions:\")\n",
    "print(\"--------------------------\")\n",
    "for text in text_list:\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(\"cuda\") # moving to mps for Mac (can alternatively do 'cpu')\n",
    "\n",
    "    logits = model(inputs).logits\n",
    "    predictions = torch.max(logits,1).indices\n",
    "\n",
    "    print(text + \" - \" + id2label[predictions.tolist()[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c084bd9e-f7b1-4979-b753-73335ee0cede",
   "metadata": {},
   "source": [
    "### Optional: push model to hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159eb49a-dd0d-4c9e-b9ab-27e06585fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 1: notebook login\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login() # ensure token gives write access\n",
    "\n",
    "# # option 2: key login\n",
    "# from huggingface_hub import login\n",
    "# write_key = 'hf_' # paste token here\n",
    "# login(write_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09496307-e253-47e3-a46f-3f28a84c89a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_name = 'shawhin' # your hf username or org name\n",
    "model_id = hf_name + \"/\" + model_checkpoint + \"-lora-text-classification\" # you can name the model whatever you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56ea581-0ea3-45f3-af21-362e9093ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub(model_id) # save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f487331a-8552-4fb2-867f-985b8fe1d1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(model_id) # save trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e7feaa-b70e-4b1d-a118-23c616d14639",
   "metadata": {},
   "source": [
    "### Optional: load peft model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cffa01-25a4-4c86-a7fa-a84353b8caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to load peft model from hub for inference\n",
    "config = PeftConfig.from_pretrained(model_id)\n",
    "inference_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    config.base_model_name_or_path, num_labels=2, id2label=id2label, label2id=label2id\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "model = PeftModel.from_pretrained(inference_model, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c6ed42-8ec3-4343-9e42-405feac052ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch-gpu-env)",
   "language": "python",
   "name": "pytorch-gpu-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
